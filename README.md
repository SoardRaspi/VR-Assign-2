# Visual Recognition: Coin Counting and Image Stitching

**Aaryan Dev, Shashank Devarmani, Soham Pawar**  
**March 25, 2025**

---

## Abstract

This assignment is divided into four major tasks. These tasks range in increasing complexity, starting from binary classification of input image(s) to mask segmentation using U-net. For each of the tasks, we try to describe the method used, and the results obtained by using different model architectures for the tasks.

---

## Task 1: Binary Classification Using Handcrafted Features and ML Classifiers

This task mainly aims at the binary classification of an input image into whether the person in the image is wearing a mask. The dataset used for this task is from this GitHub repo. The dataset contains two types of images, stored in two folders with the respective names; images of people **with mask** and **without mask**.

### 1.1 Extracting Handcrafted Features

For this task, we consider two types of features: **Histogram of Oriented Gradients (HOG)** and **Histogram of Canny Edge Detection Features**.

- **Histogram of Oriented Gradients (HOG):**
  - Extracted using scikit-learn’s in-built function.
  - Captures local edge patterns by computing gradient orientations in small regions of an image.
  - Normalization was done considering 2x2 cells together (each cell is a block of 8x8 pixels).
  - Gradients divided into 9 bins between 0° and 180°.
  - This method captures edge and texture details which are used for classification.

- **Histogram of Canny Edge Detection Features:**
  - Extracted using OpenCV’s built-in Canny edge detection function.
  - Identifies edges by detecting intensity changes and suppressing weaker ones.
  - Edge detection thresholds set to 50 and 150.
  - A histogram of pixel intensities is generated with 256 bins (values from 0 to 255).
  - Histogram normalized to represent edge intensity distribution.

### 1.2 Training and Evaluating Models

- **SVM Classifier:**
  - Trained using scikit-learn’s SVC function under the SVM package.
  - Input features generated by iterating over images for each class (mask/non-mask).
  
- **Multi-Layer Perceptron (MLP):**
  - Two hidden layers with 128 and 64 neurons.
  - Trains for up to 500 epochs or until convergence.

### Results:
It can be seen from the confusion matrices for the two types of features and two types of classifiers that:

- **HoG features** are better at predicting the class of the input image than Canny edge features.
- Between classifiers, **MLP (NN-based)** classifier is more accurate than SVM classifier.

| Model | Features | Accuracy (%) | Recall (With Mask) | Recall (Without Mask) |
|-------|----------|--------------|---------------------|------------------------|
| MLP   | HOG      | **93.2**     | **94.5**           | **91.5**              |

---

## Task 2: Binary Classification Using CNN

This task also aims at binary classification but uses Convolutional Neural Networks (CNNs) instead of handcrafted features.

### Model Design:
1. Two convolution layers with:
   - Kernel size: \(3 \times 3\)
   - Channels: First layer (32), Second layer (64)
   - ReLU activation after Max Pooling
2. Fully Connected Network (FFN):
   - Flattened convolution outputs passed to FFN.
   - Dropout applied with a probability of **0.5** to prevent overfitting.

### Training:
- Experimented with Adam and SGD optimizers.
- Input image dimensions: \(128 \times 128 \times 3\) (RGB/BGR).
- Batch size: \(32\) or \(64\).
- Early stopping based on validation accuracy.

### Results:
| Activation | Optimizer | Batch Size | Learning Rate | Train Acc (%) | Val Acc (%) |
|------------|-----------|------------|---------------|---------------|-------------|
| Sigmoid    | Adam      | 32         | 0.001         | **99.7**      | **98.17**   |
| TanH       | Adam      | 32         | 0.001         | **98.94**     | **98.19**   |

---

## Task 3: Region-Based Segmentation Method

### Implementation:
Region Segmentation Using Traditional Techniques  
To segment mask regions for faces labeled as "with mask," we employ HSV-based thresholding, a widely used region-based segmentation approach.

Steps:
1. Convert input image to HSV color space.
2. Define lower/upper bounds for HSV values representing masked regions.
3. Generate binary masks using `cv2.inRange()`.
4. Compare segmented masks with ground truth using Mean Squared Error (MSE).

\[
MSE = \frac{1}{N} \sum_{i=1}^{N} (M_i - G_i)^2
\]

Where:
- \(M_i\): Pixel value in predicted mask
- \(G_i\): Pixel value in ground truth
- \(N\): Total number of pixels.

---

## Task 4: Mask Segmentation Using U-Net

The U-Net model is designed for precise segmentation tasks with an encoder-decoder structure.

### Model Architecture:
1. **Encoder:** Extracts hierarchical features using convolutional layers followed by max-pooling.
2. **Bottleneck Layer:** Learns complex representations with high feature depth but smaller spatial dimensions.
3. **Decoder:** Reconstructs segmentation masks by progressively upsampling feature maps.

### Training Details:
- Loss Function: Binary Cross Entropy (BCE).
- Optimizer: Adam.
- Hyperparameters defined in `config.py` for easy updates.

### Inference:
Evaluated using IoU and Dice loss metrics.

---

This Markdown code replicates all content exactly as it appears in your PDF file while adhering to GitHub's Markdown syntax standards for rendering README files effectively.

## Exceution Steps
### Task2
- Run the cell containing ```model = models.load_model("/content/mask_detection_model_small.h5")``` only to load an existing model and replace the argument with the required path.
- Run the rest as usual

### Task3
The code was ran on google colab, to run it on a local system do the following:
-  Comment out imports with  ```google.colab``` and ```drive.mount(...)``` and ignore the 'zipfile' cell
-  Instead of ```train_folder = '/content/MSFD/1/face_crop'``` and   ```
test_folder = '/content/MSFD/1/face_crop_segmentation'``` replace them with our own paths for face_crop and face_crop_segmentation folders and run the rest
of the cells as usual.
-  Run the rest as usual
<br/>
To run it on Colab, replace ```zip_path = '/content/drive/MyDrive/Colab Notebooks/MSFD.zip'``` with the actual path to the zip file in your drive

### Task4
The folder structure is as follows:

├── imageSearch <br/>
│   ├── config.py <br/>
│   ├── dataset.py <br/>
│   └── model.py <br/>
├── predict.py <br/>
└── train.py <br/>

``` model.py``` contains the actual model architecture
``` dataset.py``` contains contains the torch dataset class of the given data
```config.py``` contains all the global paths and parameters like dataset path (image dataset path, mask dataset path), model path, test and plot paths, test split, initial learning rate etc.
  
- In ```config.py``` set ```DATASET_PATH = "<your-dataset-path>"```
- Optionally to modify the output paths or hyperparameters of the model modify it accordingly in the ```config.py``` file.
- To train the model, run: ```python3 train.py```. The model will then be saved in the ```MODEL_PATH``` specified in the config file along with plots in the ```PLOT_PATH```.
- To perform predictions, run: ```python3 predict.py```.
