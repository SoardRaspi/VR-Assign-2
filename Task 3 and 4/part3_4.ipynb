{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fd77d5a",
      "metadata": {
        "id": "7fd77d5a"
      },
      "source": [
        "# Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87695476",
      "metadata": {
        "id": "87695476"
      },
      "source": [
        "## Region-Based Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54017f82",
      "metadata": {
        "id": "54017f82"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# access google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41bee87",
      "metadata": {
        "id": "b41bee87"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/MSFD.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/') # Extracts to the current working directory (/content/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4fda3f",
      "metadata": {
        "id": "2e4fda3f"
      },
      "source": [
        "### Otsu thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbdeafa",
      "metadata": {
        "id": "9bbdeafa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "def calculate_IoU(original_image, thresholded_image):\n",
        "    # Compute IoU\n",
        "    # Reshape to the shape fo the thresholded_image\n",
        "    original_image = cv2.resize(original_image, (thresholded_image.shape[1], thresholded_image.shape[0]))\n",
        "    intersection = np.logical_and(original_image, thresholded_image)\n",
        "    union = np.logical_or(original_image, thresholded_image)\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n",
        "\n",
        "def calculate_Dice(original_image, thresholded_image):\n",
        "    # calculate dice score\n",
        "    # Reshape to the shape fo the thresholded_image\n",
        "    original_image = cv2.resize(original_image, (thresholded_image.shape[1], thresholded_image.shape[0]))\n",
        "    intersection = np.logical_and(original_image, thresholded_image)\n",
        "    dice_score = 2.0 * np.sum(intersection) / (np.sum(original_image) + np.sum(thresholded_image))\n",
        "    return dice_score\n",
        "\n",
        "train_folder = '/content/MSFD/1/face_crop'\n",
        "test_folder = '/content/MSFD/1/face_crop_segmentation'\n",
        "\n",
        "train_images = os.listdir(train_folder)\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# Create sets for quick lookup\n",
        "test_image_set = set(test_images)\n",
        "\n",
        "total_iou = 0\n",
        "total_dice = 0\n",
        "image_count = 0\n",
        "unmatched_count = 0\n",
        "\n",
        "for train_filename in train_images:\n",
        "    if train_filename in test_image_set:\n",
        "        image_path = os.path.join(train_folder, train_filename)\n",
        "        gt_path = os.path.join(test_folder, train_filename)\n",
        "\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is not None and gt is not None:\n",
        "            # Apply Otsu's thresholding\n",
        "            _, thresholded_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "            iou = calculate_IoU(gt, thresholded_image)\n",
        "            total_iou += iou\n",
        "            dice = calculate_Dice(gt, thresholded_image)\n",
        "            total_dice += dice\n",
        "            image_count += 1\n",
        "    else:\n",
        "        unmatched_count += 1\n",
        "\n",
        "if image_count > 0:\n",
        "    average_iou = total_iou / image_count\n",
        "    average_dice = total_dice / image_count\n",
        "    print(\"IoU for Otsu thresholding:\", average_iou)\n",
        "    print(\"Dice for Otsu thresholding:\", average_dice)\n",
        "    print(\"Unmatched images:\", unmatched_count)\n",
        "else:\n",
        "    print(\"No matching images found in the specified folders.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86897141",
      "metadata": {
        "id": "86897141"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdc1387",
      "metadata": {
        "id": "abdc1387"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68aa7f23",
      "metadata": {
        "id": "68aa7f23"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a5960f",
      "metadata": {
        "id": "59a5960f"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "385e54b5",
      "metadata": {
        "id": "385e54b5"
      },
      "outputs": [],
      "source": [
        "!pip install imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1542ffdf",
      "metadata": {
        "id": "1542ffdf"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8445d15",
      "metadata": {
        "id": "e8445d15"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b55f9c7",
      "metadata": {
        "id": "0b55f9c7"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca65966",
      "metadata": {
        "id": "1ca65966"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Correct path with the right filename (MSFD.zip not MFSD.zip)\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/MSFD.zip'\n",
        "\n",
        "# Create the extraction directory\n",
        "os.makedirs('MFSD', exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        print(\"Extracting files... (this may take a while as the file is ~2.25GB)\")\n",
        "        zip_ref.extractall('MFSD')\n",
        "    print('Extraction complete!')\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {zip_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"The file is not a valid zip file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0801455f",
      "metadata": {
        "id": "0801455f"
      },
      "outputs": [],
      "source": [
        "# Print the current content of your config.py file\n",
        "!cat /content/imageSearch/config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080112ea",
      "metadata": {
        "id": "080112ea"
      },
      "outputs": [],
      "source": [
        "# Create a new config.py file with all the necessary variables\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(\"\"\"\n",
        "import os\n",
        "\n",
        "# Define the path to the dataset\n",
        "DATASET_PATH = \"MFSD\"\n",
        "\n",
        "# Define the path to the images and masks dataset\n",
        "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"masks\")\n",
        "\n",
        "# Define the test split\n",
        "TEST_SPLIT = 0.15\n",
        "\n",
        "# Determine the device to be used for training and evaluation\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\n",
        "# Define the number of channels in the input, number of classes,\n",
        "# and number of levels in the U-Net model\n",
        "NUM_CHANNELS = 1\n",
        "NUM_CLASSES = 1\n",
        "NUM_LEVELS = 3\n",
        "\n",
        "# Initialize learning rate, number of epochs to train for, and the\n",
        "# batch size\n",
        "INIT_LR = 0.001\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Define the input image dimensions\n",
        "INPUT_IMAGE_WIDTH = 128\n",
        "INPUT_IMAGE_HEIGHT = 128\n",
        "\n",
        "# Define threshold to filter weak predictions\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "\n",
        "# Define the path to the output serialized model, model training\n",
        "# plot, and testing image paths\n",
        "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet_face_mask.pth\")\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(BASE_OUTPUT, exist_ok=True)\n",
        "\"\"\")\n",
        "\n",
        "print(\"Created a new config.py file with all required variables\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e879c2",
      "metadata": {
        "id": "84e879c2"
      },
      "outputs": [],
      "source": [
        "# Print the import statements from your train.py\n",
        "!head -20 /content/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2b534a",
      "metadata": {
        "id": "db2b534a"
      },
      "outputs": [],
      "source": [
        "!pip install imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc0f651f",
      "metadata": {
        "id": "cc0f651f"
      },
      "outputs": [],
      "source": [
        "# Update the paths in your config file based on your folder structure\n",
        "with open('/content/imageSearch/config.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace the path variables with the correct ones\n",
        "content = content.replace(\n",
        "    'DATASET_PATH = \"MFSD\"',\n",
        "    'DATASET_PATH = \"MFSD/MSFD/1\"'  # Point to the \"1\" folder inside MSFD\n",
        ")\n",
        "content = content.replace(\n",
        "    'IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")',\n",
        "    'IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop\")'  # Assuming this is where the input images are\n",
        ")\n",
        "content = content.replace(\n",
        "    'MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"masks\")',\n",
        "    'MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop_segmentation\")'  # Assuming this is where the masks are\n",
        ")\n",
        "\n",
        "# Write the updated content back\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Updated config.py with corrected paths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e27839",
      "metadata": {
        "id": "40e27839"
      },
      "outputs": [],
      "source": [
        "# Count image files in the expected locations\n",
        "!ls -la MFSD/MSFD/1/face_crop | head -5\n",
        "!ls -la MFSD/MSFD/1/face_crop_segmentation | head -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457eb51e",
      "metadata": {
        "id": "457eb51e"
      },
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e87ee5",
      "metadata": {
        "id": "57e87ee5"
      },
      "outputs": [],
      "source": [
        "!ls -la output/unet_face_mask.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a51a1528",
      "metadata": {
        "id": "a51a1528"
      },
      "outputs": [],
      "source": [
        "# Update the config.py file to include the DEVICE variable\n",
        "with open('/content/imageSearch/config.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Check if DEVICE is already defined\n",
        "if 'DEVICE =' not in content:\n",
        "    # Add the device configuration\n",
        "    device_config = \"\"\"\n",
        "# Determine the device to be used for training and evaluation\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\"\"\"\n",
        "\n",
        "    # Add it after the imports\n",
        "    if 'import os' in content:\n",
        "        content = content.replace('import os', 'import os\\nimport torch')\n",
        "        # Add the device config after the path definitions\n",
        "        if 'MASK_DATASET_PATH =' in content:\n",
        "            content = content.replace('MASK_DATASET_PATH =', 'MASK_DATASET_PATH =\\n\\n' + device_config.strip() + '\\n\\n# MASK_DATASET_PATH =')\n",
        "        else:\n",
        "            # If no MASK_DATASET_PATH, add it at the end\n",
        "            content += '\\n' + device_config\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/imageSearch/config.py', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "print(\"Updated config.py with DEVICE variable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106243f1",
      "metadata": {
        "id": "106243f1"
      },
      "outputs": [],
      "source": [
        "# Create a fresh, error-free config.py file\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(\"\"\"import os\n",
        "import torch\n",
        "\n",
        "# Define the path to the dataset\n",
        "DATASET_PATH = \"MFSD/MSFD/1\"\n",
        "\n",
        "# Define the path to the images and masks dataset\n",
        "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop\")\n",
        "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop_segmentation\")\n",
        "\n",
        "# Define the test split\n",
        "TEST_SPLIT = 0.15\n",
        "\n",
        "# Determine the device to be used for training and evaluation\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\n",
        "# Define the number of channels in the input, number of classes,\n",
        "# and number of levels in the U-Net model\n",
        "NUM_CHANNELS = 1\n",
        "NUM_CLASSES = 1\n",
        "NUM_LEVELS = 3\n",
        "\n",
        "# Initialize learning rate, number of epochs to train for, and the\n",
        "# batch size\n",
        "INIT_LR = 0.001\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Define the input image dimensions\n",
        "INPUT_IMAGE_WIDTH = 128\n",
        "INPUT_IMAGE_HEIGHT = 128\n",
        "\n",
        "# Define threshold to filter weak predictions\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "\n",
        "# Define the path to the output serialized model, model training\n",
        "# plot, and testing image paths\n",
        "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet_face_mask.pth\")\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(BASE_OUTPUT, exist_ok=True)\n",
        "\"\"\")\n",
        "\n",
        "print(\"Created a fresh config.py file without syntax errors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f675c6b",
      "metadata": {
        "id": "7f675c6b"
      },
      "outputs": [],
      "source": [
        "# Add IoU and Dice score calculations to predict.py\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Add the calculation functions\n",
        "metrics_code = \"\"\"\n",
        "# Calculate IoU (Intersection over Union)\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    return iou\n",
        "\n",
        "# Calculate Dice coefficient\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and sum of areas\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "\n",
        "    # Calculate Dice\n",
        "    dice = (2 * intersection) / sum_areas if sum_areas > 0 else 0\n",
        "    return dice\n",
        "\"\"\"\n",
        "\n",
        "# Find a good place to insert the metrics code (after imports)\n",
        "if 'import os' in content:\n",
        "    content = content.replace('import os', 'import os\\n' + metrics_code)\n",
        "else:\n",
        "    # Add it after the numpy import\n",
        "    content = content.replace('import numpy as np', 'import numpy as np\\n' + metrics_code)\n",
        "\n",
        "# Modify the make_predictions function to calculate and display the metrics\n",
        "if 'make_predictions' in content and 'prepare_plot' in content:\n",
        "    # Update prepare_plot to include metrics\n",
        "    content = content.replace(\n",
        "        'def prepare_plot(origImage, origMask, predMask):',\n",
        "        'def prepare_plot(origImage, origMask, predMask, iou, dice):'\n",
        "    )\n",
        "\n",
        "    content = content.replace(\n",
        "        'ax[2].set_title(\"Predicted Mask\")',\n",
        "        'ax[2].set_title(f\"Predicted Mask\\\\nIoU: {iou:.4f}, Dice: {dice:.4f}\")'\n",
        "    )\n",
        "\n",
        "    # Update make_predictions to calculate metrics\n",
        "    metrics_calculation = \"\"\"\n",
        "        # Calculate IoU and Dice scores\n",
        "        iou = calculate_iou(predMask, gtMask)\n",
        "        dice = calculate_dice(predMask, gtMask)\n",
        "        print(f\"IoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
        "\n",
        "        # prepare a plot for visualization\n",
        "        prepare_plot(orig, gtMask, predMask, iou, dice)\n",
        "\"\"\"\n",
        "\n",
        "    # Find where to insert the metrics calculation\n",
        "    if 'prepare_plot(orig, gtMask, predMask)' in content:\n",
        "        content = content.replace(\n",
        "            'prepare_plot(orig, gtMask, predMask)',\n",
        "            metrics_calculation.strip()\n",
        "        )\n",
        "\n",
        "# Write the modified content back\n",
        "with open('/content/predict.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Added IoU and Dice score calculations to predict.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b1c398",
      "metadata": {
        "id": "b4b1c398"
      },
      "outputs": [],
      "source": [
        "# Update the main part of predict.py to calculate average metrics\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Add code to keep track of average metrics\n",
        "if \"for path in imagePaths:\" in content:\n",
        "    # Find the section before the loop\n",
        "    before_loop = content.split(\"for path in imagePaths:\")[0]\n",
        "    # Find the section with the loop\n",
        "    loop_section = \"for path in imagePaths:\" + content.split(\"for path in imagePaths:\")[1]\n",
        "\n",
        "    # Add metrics tracking code before the loop\n",
        "    metrics_tracking = \"\"\"\n",
        "# Initialize lists to store metrics\n",
        "all_ious = []\n",
        "all_dice_scores = []\n",
        "\n",
        "\"\"\"\n",
        "    updated_content = before_loop + metrics_tracking + loop_section\n",
        "\n",
        "    # Update the loop to collect metrics\n",
        "    updated_content = updated_content.replace(\n",
        "        \"make_predictions(unet, path)\",\n",
        "        \"iou, dice = make_predictions(unet, path)\\nall_ious.append(iou)\\nall_dice_scores.append(dice)\"\n",
        "    )\n",
        "\n",
        "    # Add code to print average metrics after the loop\n",
        "    updated_content += \"\"\"\n",
        "# Calculate and print average metrics\n",
        "avg_iou = sum(all_ious) / len(all_ious) if all_ious else 0\n",
        "avg_dice = sum(all_dice_scores) / len(all_dice_scores) if all_dice_scores else 0\n",
        "print(f\"\\\\nAverage metrics across {len(all_ious)} images:\")\n",
        "print(f\"Average IoU: {avg_iou:.4f}\")\n",
        "print(f\"Average Dice score: {avg_dice:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(updated_content)\n",
        "\n",
        "    print(\"Updated predict.py to calculate average metrics\")\n",
        "\n",
        "# Also modify make_predictions to return the calculated metrics\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "if \"def make_predictions\" in content and \"return\" not in content:\n",
        "    # Add return statement to make_predictions\n",
        "    content = content.replace(\n",
        "        \"prepare_plot(orig, gtMask, predMask, iou, dice)\",\n",
        "        \"prepare_plot(orig, gtMask, predMask, iou, dice)\\n\\t\\treturn iou, dice\"\n",
        "    )\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "    print(\"Modified make_predictions to return metrics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaad7d0",
      "metadata": {
        "id": "ddaad7d0"
      },
      "outputs": [],
      "source": [
        "# Fix the indentation in predict.py\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace all tabs with 4 spaces to standardize indentation\n",
        "content = content.replace('\\t', '    ')\n",
        "\n",
        "# Write the standardized content back\n",
        "with open('/content/predict.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Fixed indentation in predict.py by replacing tabs with spaces\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3f24fd",
      "metadata": {
        "id": "7e3f24fd"
      },
      "outputs": [],
      "source": [
        "# Check if test paths file exists and what it contains\n",
        "!cat output/test_paths.txt | wc -l\n",
        "!head -5 output/test_paths.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc30e95",
      "metadata": {
        "id": "dcc30e95"
      },
      "outputs": [],
      "source": [
        "# First, let's check if our modified predict.py is trying to calculate IoU\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Check if the IoU calculation functions are defined\n",
        "if 'calculate_iou' not in content:\n",
        "    # Add the IoU and Dice calculation functions\n",
        "    metrics_code = \"\"\"\n",
        "# Calculate IoU (Intersection over Union)\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    return iou\n",
        "\n",
        "# Calculate Dice coefficient\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and sum of areas\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "\n",
        "    # Calculate Dice\n",
        "    dice = (2 * intersection) / sum_areas if sum_areas > 0 else 0\n",
        "    return dice\n",
        "\"\"\"\n",
        "    # Add after imports but before other functions\n",
        "    if \"import cv2\" in content:\n",
        "        content = content.replace(\"import cv2\", \"import cv2\\n\" + metrics_code)\n",
        "    else:\n",
        "        content = content.replace(\"import numpy as np\", \"import numpy as np\\n\" + metrics_code)\n",
        "\n",
        "    # Write back to the file\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "    print(\"Added IoU and Dice calculation functions\")\n",
        "\n",
        "# Now let's modify the make_predictions function to calculate and print IoU\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Find the make_predictions function\n",
        "make_predictions_start = content.find(\"def make_predictions\")\n",
        "if make_predictions_start != -1:\n",
        "    # Check if it already has IoU calculation\n",
        "    if \"calculate_iou\" not in content[make_predictions_start:]:\n",
        "        # Find where to add IoU calculation (right before prepare_plot)\n",
        "        prepare_plot_pos = content.find(\"prepare_plot\", make_predictions_start)\n",
        "        if prepare_plot_pos != -1:\n",
        "            # Insert IoU calculation before prepare_plot\n",
        "            iou_code = \"\"\"\n",
        "        # Calculate IoU and Dice scores\n",
        "        iou = calculate_iou(predMask, gtMask)\n",
        "        dice = calculate_dice(predMask, gtMask)\n",
        "        print(f\"File: {filename}, IoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
        "\n",
        "        \"\"\"\n",
        "            # Split content to insert our code\n",
        "            content_before = content[:prepare_plot_pos]\n",
        "            content_after = content[prepare_plot_pos:]\n",
        "            # Combine with our IoU code\n",
        "            content = content_before + iou_code + content_after\n",
        "\n",
        "            # Write back to the file\n",
        "            with open('/content/predict.py', 'w') as file:\n",
        "                file.write(content)\n",
        "            print(\"Modified make_predictions to calculate and print IoU\")\n",
        "\n",
        "# Make sure prepare_plot accepts IoU parameters\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "if \"def prepare_plot\" in content:\n",
        "    # Update the prepare_plot function signature and implementation\n",
        "    prepare_plot_start = content.find(\"def prepare_plot\")\n",
        "    prepare_plot_end = content.find(\"def\", prepare_plot_start + 1)\n",
        "    if prepare_plot_end == -1:  # If it's the last function\n",
        "        prepare_plot_end = len(content)\n",
        "\n",
        "    # Create updated prepare_plot function\n",
        "    updated_prepare_plot = \"\"\"\n",
        "def prepare_plot(origImage, origMask, predMask, iou=None, dice=None, imagePath=None):\n",
        "    # initialize our figure\n",
        "    figure, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "    # plot the original image, its mask, and the predicted mask\n",
        "    ax[0].imshow(origImage)\n",
        "    ax[1].imshow(origMask, cmap='gray')\n",
        "    ax[2].imshow(predMask, cmap='gray')\n",
        "    # set the titles of the subplots\n",
        "    ax[0].set_title(\"Image\")\n",
        "    ax[1].set_title(\"Original Mask\")\n",
        "    title = \"Predicted Mask\"\n",
        "    if iou is not None and dice is not None:\n",
        "        title = f\"Predicted Mask\\\\nIoU: {iou:.4f}, Dice: {dice:.4f}\"\n",
        "    ax[2].set_title(title)\n",
        "    # set the layout of the figure and display it\n",
        "    figure.tight_layout()\n",
        "    figure.show()\n",
        "\n",
        "    # Save the figure if imagePath is provided\n",
        "    if imagePath:\n",
        "        os.makedirs(\"visualizations\", exist_ok=True)\n",
        "        save_path = os.path.join(\"visualizations\", f\"segmentation_{os.path.basename(imagePath).split('.')[0]}.png\")\n",
        "        figure.savefig(save_path)\n",
        "        print(f\"Visualization saved to {save_path}\")\n",
        "\"\"\"\n",
        "\n",
        "    # Replace the old function with our updated one\n",
        "    content = content[:prepare_plot_start] + updated_prepare_plot + content[prepare_plot_end:]\n",
        "\n",
        "    # Write back to the file\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "    print(\"Updated prepare_plot function to display IoU and Dice scores\")\n",
        "\n",
        "# Make sure the make_predictions function returns IoU and Dice\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Find make_predictions function\n",
        "make_predictions_start = content.find(\"def make_predictions\")\n",
        "if make_predictions_start != -1:\n",
        "    # If there's no return statement, add one\n",
        "    if \"return iou, dice\" not in content[make_predictions_start:]:\n",
        "        # Find the end of the function\n",
        "        next_def = content.find(\"def\", make_predictions_start + 1)\n",
        "        if next_def == -1:\n",
        "            next_def = len(content)\n",
        "\n",
        "        # Check if there's a prepare_plot call\n",
        "        prepare_plot_pos = content.rfind(\"prepare_plot\", make_predictions_start, next_def)\n",
        "        if prepare_plot_pos != -1:\n",
        "            # Find the end of this line\n",
        "            line_end = content.find(\"\\n\", prepare_plot_pos)\n",
        "            if line_end != -1:\n",
        "                # Insert return statement after prepare_plot call\n",
        "                content = content[:line_end+1] + \"        return iou, dice\\n\" + content[line_end+1:]\n",
        "\n",
        "                # Write back to the file\n",
        "                with open('/content/predict.py', 'w') as file:\n",
        "                    file.write(content)\n",
        "                print(\"Added return statement to make_predictions function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e9337f",
      "metadata": {
        "id": "03e9337f"
      },
      "outputs": [],
      "source": [
        "!python predict.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}