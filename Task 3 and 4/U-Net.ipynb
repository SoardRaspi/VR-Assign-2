{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WzAW0J9ouPk",
        "outputId": "d9958efb-ffd3-48d0-d4c9-d271f6b98965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxQJrXrEqb4s",
        "outputId": "93f80415-793e-4c3e-dcf0-49b8aaa8eaae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBG_U-9aqgWg",
        "outputId": "d176cea1-9b6c-4491-9ce5-968d0411c7f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAsu836LqjOR",
        "outputId": "cd10b82e-929a-4ec9-e91a-302487faea49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0o6zTPGqkyw",
        "outputId": "114932f9-50fb-400e-a3e6-075d7472900c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvditdegqpCq",
        "outputId": "d5ee1f9e-32ac-4fac-980b-cc85aef8b22e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUxKgZ1qSBJL",
        "outputId": "b304e450-c478-4361-db50-5a3081633ee4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Correct path with the right filename (MSFD.zip not MFSD.zip)\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/MSFD.zip'\n",
        "\n",
        "# Create the extraction directory\n",
        "os.makedirs('MFSD', exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        print(\"Extracting files... (this may take a while as the file is ~2.25GB)\")\n",
        "        zip_ref.extractall('MFSD')\n",
        "    print('Extraction complete!')\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {zip_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"The file is not a valid zip file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wigRWc1YS5Z0",
        "outputId": "3f43d40c-66aa-42b7-8966-cccc7a025021"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files... (this may take a while as the file is ~2.25GB)\n",
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the current content of your config.py file\n",
        "!cat /content/imageSearch/config.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfTZJwUYTmYa",
        "outputId": "aa453ef5-0fb3-466f-b24f-92510b3991a0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# define the number of channels in the input, number of classes,\n",
            "# and number of levels in the U-Net model\n",
            "NUM_CHANNELS = 1\n",
            "NUM_CLASSES = 1\n",
            "NUM_LEVELS = 3\n",
            "# initialize learning rate, number of epochs to train for, and the\n",
            "# batch size\n",
            "INIT_LR = 0.001\n",
            "NUM_EPOCHS = 40\n",
            "BATCH_SIZE = 64\n",
            "# define the input image dimensions\n",
            "INPUT_IMAGE_WIDTH = 128\n",
            "INPUT_IMAGE_HEIGHT = 128\n",
            "# define threshold to filter weak predictions\n",
            "THRESHOLD = 0.5\n",
            "# define the path to the base output directory\n",
            "BASE_OUTPUT = \"output\"\n",
            "# define the path to the output serialized model, model training\n",
            "# plot, and testing image paths\n",
            "\n",
            "import os\n",
            "\n",
            "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet_tgs_salt.pth\")\n",
            "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
            "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
            "\n",
            "# Edit the config.py file to add the missing path variables\n",
            "with open('/content/imageSearch/config.py', 'r') as file:\n",
            "    content = file.read()\n",
            "\n",
            "# Add the necessary path variables if they don't exist\n",
            "required_paths = \"\"\"\n",
            "# Define the path to the dataset\n",
            "DATASET_PATH = \"MFSD\"\n",
            "# Define the path to the images and masks dataset\n",
            "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")\n",
            "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"masks\")\n",
            "\"\"\"\n",
            "\n",
            "# Check if import os is in the file\n",
            "if 'import os' not in content:\n",
            "    content = 'import os\\n' + content\n",
            "\n",
            "# Check if the path variables are already defined\n",
            "if 'IMAGE_DATASET_PATH' not in content:\n",
            "    content += required_paths\n",
            "\n",
            "# Write the updated content back\n",
            "with open('/content/imageSearch/config.py', 'w') as file:\n",
            "    file.write(content)\n",
            "\n",
            "print(\"Updated config.py with required path variables\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new config.py file with all the necessary variables\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(\"\"\"\n",
        "import os\n",
        "\n",
        "# Define the path to the dataset\n",
        "DATASET_PATH = \"MFSD\"\n",
        "\n",
        "# Define the path to the images and masks dataset\n",
        "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"masks\")\n",
        "\n",
        "# Define the test split\n",
        "TEST_SPLIT = 0.15\n",
        "\n",
        "# Determine the device to be used for training and evaluation\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\n",
        "# Define the number of channels in the input, number of classes,\n",
        "# and number of levels in the U-Net model\n",
        "NUM_CHANNELS = 1\n",
        "NUM_CLASSES = 1\n",
        "NUM_LEVELS = 3\n",
        "\n",
        "# Initialize learning rate, number of epochs to train for, and the\n",
        "# batch size\n",
        "INIT_LR = 0.001\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Define the input image dimensions\n",
        "INPUT_IMAGE_WIDTH = 128\n",
        "INPUT_IMAGE_HEIGHT = 128\n",
        "\n",
        "# Define threshold to filter weak predictions\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "\n",
        "# Define the path to the output serialized model, model training\n",
        "# plot, and testing image paths\n",
        "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet_face_mask.pth\")\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(BASE_OUTPUT, exist_ok=True)\n",
        "\"\"\")\n",
        "\n",
        "print(\"Created a new config.py file with all required variables\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCcUxUK0Tv2Z",
        "outputId": "464a6aa8-415b-41bc-b64b-2383ac7e7e2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a new config.py file with all required variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the import statements from your train.py\n",
        "!head -20 /content/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djqmkUBGT1i9",
        "outputId": "ca39a829-dfbb-4fa3-b35b-310a8b983744"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# USAGE\n",
            "# python train.py\n",
            "# import the necessary packages\n",
            "from imageSearch.dataset import SegmentationDataset\n",
            "from imageSearch.model import UNet\n",
            "from imageSearch import config\n",
            "from torch.nn import BCEWithLogitsLoss\n",
            "from torch.optim import Adam\n",
            "from torch.utils.data import DataLoader\n",
            "from sklearn.model_selection import train_test_split\n",
            "from torchvision import transforms\n",
            "from imutils import paths\n",
            "from tqdm import tqdm\n",
            "import matplotlib.pyplot as plt\n",
            "import torch\n",
            "import time\n",
            "import os\n",
            "\n",
            "# load the image and mask filepaths in a sorted manner\n",
            "imagePaths = sorted(list(paths.list_images(config.IMAGE_DATASET_PATH)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnrohOhpT2T7",
        "outputId": "d2cbdceb-0784-4c43-d9ae-b92a30299c6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the paths in your config file based on your folder structure\n",
        "with open('/content/imageSearch/config.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace the path variables with the correct ones\n",
        "content = content.replace(\n",
        "    'DATASET_PATH = \"MFSD\"',\n",
        "    'DATASET_PATH = \"MFSD/MSFD/1\"'  # Point to the \"1\" folder inside MSFD\n",
        ")\n",
        "content = content.replace(\n",
        "    'IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")',\n",
        "    'IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop\")'  # Assuming this is where the input images are\n",
        ")\n",
        "content = content.replace(\n",
        "    'MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"masks\")',\n",
        "    'MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop_segmentation\")'  # Assuming this is where the masks are\n",
        ")\n",
        "\n",
        "# Write the updated content back\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Updated config.py with corrected paths\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6_YuIFLUw1S",
        "outputId": "981b38b5-12ba-47c9-833b-5057b4e59d65"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated config.py with corrected paths\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count image files in the expected locations\n",
        "!ls -la MFSD/MSFD/1/face_crop | head -5\n",
        "!ls -la MFSD/MSFD/1/face_crop_segmentation | head -5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKhftsfGU0fU",
        "outputId": "2b0f7c2f-6613-4e95-afc6-1f46fcf0a106"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 605876\n",
            "drwxr-xr-x 2 root root 274432 Mar 22 18:45 .\n",
            "drwxr-xr-x 5 root root   4096 Mar 22 18:45 ..\n",
            "-rw-r--r-- 1 root root  43595 Mar 22 19:19 000000_1.jpg\n",
            "-rw-r--r-- 1 root root   2390 Mar 22 19:19 000001_1.jpg\n",
            "total 74408\n",
            "drwxr-xr-x 2 root root 274432 Mar 22 18:45 .\n",
            "drwxr-xr-x 5 root root   4096 Mar 22 18:45 ..\n",
            "-rw-r--r-- 1 root root   5926 Mar 22 19:19 000000_1.jpg\n",
            "-rw-r--r-- 1 root root   1039 Mar 22 19:19 000001_1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6ZvC8w5Q5qy",
        "outputId": "66a84742-0679-4598-e70a-ec0943821d03"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] saving testing image paths...\n",
            "[INFO] found 7975 examples in the training set...\n",
            "[INFO] found 1408 examples in the test set...\n",
            "[INFO] training the network...\n",
            "  0% 0/40 [00:00<?, ?it/s][INFO] EPOCH: 1/40\n",
            "Train loss: 0.578668, Test loss: 0.5364\n",
            "  2% 1/40 [00:47<30:50, 47.44s/it][INFO] EPOCH: 2/40\n",
            "Train loss: 0.519805, Test loss: 0.4964\n",
            "  5% 2/40 [01:29<27:52, 44.01s/it][INFO] EPOCH: 3/40\n",
            "Train loss: 0.499576, Test loss: 0.4973\n",
            "  8% 3/40 [02:10<26:24, 42.83s/it][INFO] EPOCH: 4/40\n",
            "Train loss: 0.475473, Test loss: 0.4552\n",
            " 10% 4/40 [02:52<25:27, 42.44s/it][INFO] EPOCH: 5/40\n",
            "Train loss: 0.457837, Test loss: 0.4430\n",
            " 12% 5/40 [03:34<24:37, 42.22s/it][INFO] EPOCH: 6/40\n",
            "Train loss: 0.447996, Test loss: 0.4502\n",
            " 15% 6/40 [04:15<23:49, 42.06s/it][INFO] EPOCH: 7/40\n",
            "Train loss: 0.442463, Test loss: 0.4475\n",
            " 18% 7/40 [04:57<23:02, 41.88s/it][INFO] EPOCH: 8/40\n",
            "Train loss: 0.435304, Test loss: 0.4252\n",
            " 20% 8/40 [05:38<22:10, 41.58s/it][INFO] EPOCH: 9/40\n",
            "Train loss: 0.427701, Test loss: 0.4222\n",
            " 22% 9/40 [06:18<21:12, 41.06s/it][INFO] EPOCH: 10/40\n",
            "Train loss: 0.424713, Test loss: 0.4170\n",
            " 25% 10/40 [06:58<20:24, 40.81s/it][INFO] EPOCH: 11/40\n",
            "Train loss: 0.423042, Test loss: 0.4250\n",
            " 28% 11/40 [07:39<19:47, 40.93s/it][INFO] EPOCH: 12/40\n",
            "Train loss: 0.418712, Test loss: 0.4164\n",
            " 30% 12/40 [08:21<19:11, 41.12s/it][INFO] EPOCH: 13/40\n",
            "Train loss: 0.415772, Test loss: 0.4165\n",
            " 32% 13/40 [09:02<18:29, 41.10s/it][INFO] EPOCH: 14/40\n",
            "Train loss: 0.413410, Test loss: 0.4111\n",
            " 35% 14/40 [09:43<17:49, 41.15s/it][INFO] EPOCH: 15/40\n",
            "Train loss: 0.409305, Test loss: 0.4072\n",
            " 38% 15/40 [10:35<18:29, 44.38s/it][INFO] EPOCH: 16/40\n",
            "Train loss: 0.407604, Test loss: 0.4073\n",
            " 40% 16/40 [11:38<19:57, 49.89s/it][INFO] EPOCH: 17/40\n",
            "Train loss: 0.405325, Test loss: 0.4090\n",
            " 42% 17/40 [12:19<18:06, 47.23s/it][INFO] EPOCH: 18/40\n",
            "Train loss: 0.403465, Test loss: 0.4027\n",
            " 45% 18/40 [13:00<16:37, 45.35s/it][INFO] EPOCH: 19/40\n",
            "Train loss: 0.403111, Test loss: 0.3990\n",
            " 48% 19/40 [13:41<15:26, 44.11s/it][INFO] EPOCH: 20/40\n",
            "Train loss: 0.400439, Test loss: 0.4068\n",
            " 50% 20/40 [14:21<14:18, 42.93s/it][INFO] EPOCH: 21/40\n",
            "Train loss: 0.399658, Test loss: 0.3987\n",
            " 52% 21/40 [15:02<13:25, 42.37s/it][INFO] EPOCH: 22/40\n",
            "Train loss: 0.398351, Test loss: 0.3986\n",
            " 55% 22/40 [15:43<12:36, 42.04s/it][INFO] EPOCH: 23/40\n",
            "Train loss: 0.396178, Test loss: 0.4003\n",
            " 57% 23/40 [16:24<11:49, 41.72s/it][INFO] EPOCH: 24/40\n",
            "Train loss: 0.395690, Test loss: 0.3921\n",
            " 60% 24/40 [17:05<11:02, 41.43s/it][INFO] EPOCH: 25/40\n",
            "Train loss: 0.393688, Test loss: 0.3934\n",
            " 62% 25/40 [17:46<10:19, 41.31s/it][INFO] EPOCH: 26/40\n",
            "Train loss: 0.391834, Test loss: 0.3925\n",
            " 65% 26/40 [18:28<09:39, 41.40s/it][INFO] EPOCH: 27/40\n",
            "Train loss: 0.390934, Test loss: 0.3943\n",
            " 68% 27/40 [19:09<08:56, 41.27s/it][INFO] EPOCH: 28/40\n",
            "Train loss: 0.389075, Test loss: 0.3914\n",
            " 70% 28/40 [19:49<08:11, 40.92s/it][INFO] EPOCH: 29/40\n",
            "Train loss: 0.387654, Test loss: 0.3961\n",
            " 72% 29/40 [20:29<07:27, 40.68s/it][INFO] EPOCH: 30/40\n",
            "Train loss: 0.386799, Test loss: 0.3914\n",
            " 75% 30/40 [21:09<06:46, 40.64s/it][INFO] EPOCH: 31/40\n",
            "Train loss: 0.387874, Test loss: 0.3919\n",
            " 78% 31/40 [21:51<06:08, 40.91s/it][INFO] EPOCH: 32/40\n",
            "Train loss: 0.387005, Test loss: 0.3908\n",
            " 80% 32/40 [22:32<05:27, 40.94s/it][INFO] EPOCH: 33/40\n",
            "Train loss: 0.383804, Test loss: 0.3883\n",
            " 82% 33/40 [23:13<04:47, 41.01s/it][INFO] EPOCH: 34/40\n",
            "Train loss: 0.384906, Test loss: 0.3887\n",
            " 85% 34/40 [23:54<04:06, 41.08s/it][INFO] EPOCH: 35/40\n",
            "Train loss: 0.382130, Test loss: 0.3865\n",
            " 88% 35/40 [24:36<03:25, 41.15s/it][INFO] EPOCH: 36/40\n",
            "Train loss: 0.381790, Test loss: 0.3941\n",
            " 90% 36/40 [25:17<02:44, 41.16s/it][INFO] EPOCH: 37/40\n",
            "Train loss: 0.380869, Test loss: 0.3851\n",
            " 92% 37/40 [25:57<02:02, 40.92s/it][INFO] EPOCH: 38/40\n",
            "Train loss: 0.379134, Test loss: 0.3859\n",
            " 95% 38/40 [26:38<01:21, 40.75s/it][INFO] EPOCH: 39/40\n",
            "Train loss: 0.379268, Test loss: 0.3860\n",
            " 98% 39/40 [27:18<00:40, 40.59s/it][INFO] EPOCH: 40/40\n",
            "Train loss: 0.379451, Test loss: 0.3873\n",
            "100% 40/40 [27:59<00:00, 41.98s/it]\n",
            "[INFO] total time taken to train the model: 1679.24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la output/unet_face_mask.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLS8O-w0cybR",
        "outputId": "3f3e9548-d8ec-49a2-e769-0dee9ced443f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 485082 Mar 22 19:59 output/unet_face_mask.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the config.py file to include the DEVICE variable\n",
        "with open('/content/imageSearch/config.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Check if DEVICE is already defined\n",
        "if 'DEVICE =' not in content:\n",
        "    # Add the device configuration\n",
        "    device_config = \"\"\"\n",
        "# Determine the device to be used for training and evaluation\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\"\"\"\n",
        "\n",
        "    # Add it after the imports\n",
        "    if 'import os' in content:\n",
        "        content = content.replace('import os', 'import os\\nimport torch')\n",
        "        # Add the device config after the path definitions\n",
        "        if 'MASK_DATASET_PATH =' in content:\n",
        "            content = content.replace('MASK_DATASET_PATH =', 'MASK_DATASET_PATH =\\n\\n' + device_config.strip() + '\\n\\n# MASK_DATASET_PATH =')\n",
        "        else:\n",
        "            # If no MASK_DATASET_PATH, add it at the end\n",
        "            content += '\\n' + device_config\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/imageSearch/config.py', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "print(\"Updated config.py with DEVICE variable\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muJ1zMtseFBp",
        "outputId": "8797400f-5e21-44f9-e6b3-cc9214a38f96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated config.py with DEVICE variable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fresh, error-free config.py file\n",
        "with open('/content/imageSearch/config.py', 'w') as file:\n",
        "    file.write(\"\"\"import os\n",
        "import torch\n",
        "\n",
        "# Define the path to the dataset\n",
        "DATASET_PATH = \"MFSD/MSFD/1\"\n",
        "\n",
        "# Define the path to the images and masks dataset\n",
        "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop\")\n",
        "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"face_crop_segmentation\")\n",
        "\n",
        "# Define the test split\n",
        "TEST_SPLIT = 0.15\n",
        "\n",
        "# Determine the device to be used for training and evaluation\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\n",
        "# Define the number of channels in the input, number of classes,\n",
        "# and number of levels in the U-Net model\n",
        "NUM_CHANNELS = 1\n",
        "NUM_CLASSES = 1\n",
        "NUM_LEVELS = 3\n",
        "\n",
        "# Initialize learning rate, number of epochs to train for, and the\n",
        "# batch size\n",
        "INIT_LR = 0.001\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Define the input image dimensions\n",
        "INPUT_IMAGE_WIDTH = 128\n",
        "INPUT_IMAGE_HEIGHT = 128\n",
        "\n",
        "# Define threshold to filter weak predictions\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "\n",
        "# Define the path to the output serialized model, model training\n",
        "# plot, and testing image paths\n",
        "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet_face_mask.pth\")\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(BASE_OUTPUT, exist_ok=True)\n",
        "\"\"\")\n",
        "\n",
        "print(\"Created a fresh config.py file without syntax errors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN8Z2SOKeGc0",
        "outputId": "fcf4776f-faca-41f6-e611-1b2711ff9ea1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a fresh config.py file without syntax errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add IoU and Dice score calculations to predict.py\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Add the calculation functions\n",
        "metrics_code = \"\"\"\n",
        "# Calculate IoU (Intersection over Union)\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    return iou\n",
        "\n",
        "# Calculate Dice coefficient\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and sum of areas\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "\n",
        "    # Calculate Dice\n",
        "    dice = (2 * intersection) / sum_areas if sum_areas > 0 else 0\n",
        "    return dice\n",
        "\"\"\"\n",
        "\n",
        "# Find a good place to insert the metrics code (after imports)\n",
        "if 'import os' in content:\n",
        "    content = content.replace('import os', 'import os\\n' + metrics_code)\n",
        "else:\n",
        "    # Add it after the numpy import\n",
        "    content = content.replace('import numpy as np', 'import numpy as np\\n' + metrics_code)\n",
        "\n",
        "# Modify the make_predictions function to calculate and display the metrics\n",
        "if 'make_predictions' in content and 'prepare_plot' in content:\n",
        "    # Update prepare_plot to include metrics\n",
        "    content = content.replace(\n",
        "        'def prepare_plot(origImage, origMask, predMask):',\n",
        "        'def prepare_plot(origImage, origMask, predMask, iou, dice):'\n",
        "    )\n",
        "\n",
        "    content = content.replace(\n",
        "        'ax[2].set_title(\"Predicted Mask\")',\n",
        "        'ax[2].set_title(f\"Predicted Mask\\\\nIoU: {iou:.4f}, Dice: {dice:.4f}\")'\n",
        "    )\n",
        "\n",
        "    # Update make_predictions to calculate metrics\n",
        "    metrics_calculation = \"\"\"\n",
        "        # Calculate IoU and Dice scores\n",
        "        iou = calculate_iou(predMask, gtMask)\n",
        "        dice = calculate_dice(predMask, gtMask)\n",
        "        print(f\"IoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
        "\n",
        "        # prepare a plot for visualization\n",
        "        prepare_plot(orig, gtMask, predMask, iou, dice)\n",
        "\"\"\"\n",
        "\n",
        "    # Find where to insert the metrics calculation\n",
        "    if 'prepare_plot(orig, gtMask, predMask)' in content:\n",
        "        content = content.replace(\n",
        "            'prepare_plot(orig, gtMask, predMask)',\n",
        "            metrics_calculation.strip()\n",
        "        )\n",
        "\n",
        "# Write the modified content back\n",
        "with open('/content/predict.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Added IoU and Dice score calculations to predict.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3x6EA8DfMO7",
        "outputId": "093ba20e-18ae-4084-b7a5-63cb5b531a79"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added IoU and Dice score calculations to predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the main part of predict.py to calculate average metrics\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Add code to keep track of average metrics\n",
        "if \"for path in imagePaths:\" in content:\n",
        "    # Find the section before the loop\n",
        "    before_loop = content.split(\"for path in imagePaths:\")[0]\n",
        "    # Find the section with the loop\n",
        "    loop_section = \"for path in imagePaths:\" + content.split(\"for path in imagePaths:\")[1]\n",
        "\n",
        "    # Add metrics tracking code before the loop\n",
        "    metrics_tracking = \"\"\"\n",
        "# Initialize lists to store metrics\n",
        "all_ious = []\n",
        "all_dice_scores = []\n",
        "\n",
        "\"\"\"\n",
        "    updated_content = before_loop + metrics_tracking + loop_section\n",
        "\n",
        "    # Update the loop to collect metrics\n",
        "    updated_content = updated_content.replace(\n",
        "        \"make_predictions(unet, path)\",\n",
        "        \"iou, dice = make_predictions(unet, path)\\nall_ious.append(iou)\\nall_dice_scores.append(dice)\"\n",
        "    )\n",
        "\n",
        "    # Add code to print average metrics after the loop\n",
        "    updated_content += \"\"\"\n",
        "# Calculate and print average metrics\n",
        "avg_iou = sum(all_ious) / len(all_ious) if all_ious else 0\n",
        "avg_dice = sum(all_dice_scores) / len(all_dice_scores) if all_dice_scores else 0\n",
        "print(f\"\\\\nAverage metrics across {len(all_ious)} images:\")\n",
        "print(f\"Average IoU: {avg_iou:.4f}\")\n",
        "print(f\"Average Dice score: {avg_dice:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(updated_content)\n",
        "\n",
        "    print(\"Updated predict.py to calculate average metrics\")\n",
        "\n",
        "# Also modify make_predictions to return the calculated metrics\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "if \"def make_predictions\" in content and \"return\" not in content:\n",
        "    # Add return statement to make_predictions\n",
        "    content = content.replace(\n",
        "        \"prepare_plot(orig, gtMask, predMask, iou, dice)\",\n",
        "        \"prepare_plot(orig, gtMask, predMask, iou, dice)\\n\\t\\treturn iou, dice\"\n",
        "    )\n",
        "\n",
        "    # Write the updated content back\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "    print(\"Modified make_predictions to return metrics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lWe3YTpfNoL",
        "outputId": "f898e8f4-01b1-47f5-c296-3e0493ba2c7c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated predict.py to calculate average metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the indentation in predict.py\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace all tabs with 4 spaces to standardize indentation\n",
        "content = content.replace('\\t', '    ')\n",
        "\n",
        "# Write the standardized content back\n",
        "with open('/content/predict.py', 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Fixed indentation in predict.py by replacing tabs with spaces\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzXIfcoGf4jt",
        "outputId": "2f47fcb2-8b17-49f5-90e6-47c8ca0cb067"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed indentation in predict.py by replacing tabs with spaces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if test paths file exists and what it contains\n",
        "!cat output/test_paths.txt | wc -l\n",
        "!head -5 output/test_paths.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuxB28VwgPEG",
        "outputId": "f9e590af-a4d6-4fb3-886b-028d91021445"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407\n",
            "MFSD/MSFD/1/face_crop/001812_2.jpg\n",
            "MFSD/MSFD/1/face_crop/007595_1.jpg\n",
            "MFSD/MSFD/1/face_crop/007380_2.jpg\n",
            "MFSD/MSFD/1/face_crop/001801_1.jpg\n",
            "MFSD/MSFD/1/face_crop/005483_1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's check if our modified predict.py is trying to calculate IoU\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Check if the IoU calculation functions are defined\n",
        "if 'calculate_iou' not in content:\n",
        "    # Add the IoU and Dice calculation functions\n",
        "    metrics_code = \"\"\"\n",
        "# Calculate IoU (Intersection over Union)\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    return iou\n",
        "\n",
        "# Calculate Dice coefficient\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    # Convert masks to binary format\n",
        "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Calculate intersection and sum of areas\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "\n",
        "    # Calculate Dice\n",
        "    dice = (2 * intersection) / sum_areas if sum_areas > 0 else 0\n",
        "    return dice\n",
        "\"\"\"\n",
        "    # Add after imports but before other functions\n",
        "    if \"import cv2\" in content:\n",
        "        content = content.replace(\"import cv2\", \"import cv2\\n\" + metrics_code)\n",
        "    else:\n",
        "        content = content.replace(\"import numpy as np\", \"import numpy as np\\n\" + metrics_code)\n",
        "\n",
        "    # Write back to the file\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "    print(\"Added IoU and Dice calculation functions\")\n",
        "\n",
        "# Now let's modify the make_predictions function to calculate and print IoU\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Find the make_predictions function\n",
        "make_predictions_start = content.find(\"def make_predictions\")\n",
        "if make_predictions_start != -1:\n",
        "    # Check if it already has IoU calculation\n",
        "    if \"calculate_iou\" not in content[make_predictions_start:]:\n",
        "        # Find where to add IoU calculation (right before prepare_plot)\n",
        "        prepare_plot_pos = content.find(\"prepare_plot\", make_predictions_start)\n",
        "        if prepare_plot_pos != -1:\n",
        "            # Insert IoU calculation before prepare_plot\n",
        "            iou_code = \"\"\"\n",
        "        # Calculate IoU and Dice scores\n",
        "        iou = calculate_iou(predMask, gtMask)\n",
        "        dice = calculate_dice(predMask, gtMask)\n",
        "        print(f\"File: {filename}, IoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
        "\n",
        "        \"\"\"\n",
        "            # Split content to insert our code\n",
        "            content_before = content[:prepare_plot_pos]\n",
        "            content_after = content[prepare_plot_pos:]\n",
        "            # Combine with our IoU code\n",
        "            content = content_before + iou_code + content_after\n",
        "\n",
        "            # Write back to the file\n",
        "            with open('/content/predict.py', 'w') as file:\n",
        "                file.write(content)\n",
        "            print(\"Modified make_predictions to calculate and print IoU\")\n",
        "\n",
        "# Make sure prepare_plot accepts IoU parameters\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "if \"def prepare_plot\" in content:\n",
        "    # Update the prepare_plot function signature and implementation\n",
        "    prepare_plot_start = content.find(\"def prepare_plot\")\n",
        "    prepare_plot_end = content.find(\"def\", prepare_plot_start + 1)\n",
        "    if prepare_plot_end == -1:  # If it's the last function\n",
        "        prepare_plot_end = len(content)\n",
        "\n",
        "    # Create updated prepare_plot function\n",
        "    updated_prepare_plot = \"\"\"\n",
        "def prepare_plot(origImage, origMask, predMask, iou=None, dice=None, imagePath=None):\n",
        "    # initialize our figure\n",
        "    figure, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "    # plot the original image, its mask, and the predicted mask\n",
        "    ax[0].imshow(origImage)\n",
        "    ax[1].imshow(origMask, cmap='gray')\n",
        "    ax[2].imshow(predMask, cmap='gray')\n",
        "    # set the titles of the subplots\n",
        "    ax[0].set_title(\"Image\")\n",
        "    ax[1].set_title(\"Original Mask\")\n",
        "    title = \"Predicted Mask\"\n",
        "    if iou is not None and dice is not None:\n",
        "        title = f\"Predicted Mask\\\\nIoU: {iou:.4f}, Dice: {dice:.4f}\"\n",
        "    ax[2].set_title(title)\n",
        "    # set the layout of the figure and display it\n",
        "    figure.tight_layout()\n",
        "    figure.show()\n",
        "\n",
        "    # Save the figure if imagePath is provided\n",
        "    if imagePath:\n",
        "        os.makedirs(\"visualizations\", exist_ok=True)\n",
        "        save_path = os.path.join(\"visualizations\", f\"segmentation_{os.path.basename(imagePath).split('.')[0]}.png\")\n",
        "        figure.savefig(save_path)\n",
        "        print(f\"Visualization saved to {save_path}\")\n",
        "\"\"\"\n",
        "\n",
        "    # Replace the old function with our updated one\n",
        "    content = content[:prepare_plot_start] + updated_prepare_plot + content[prepare_plot_end:]\n",
        "\n",
        "    # Write back to the file\n",
        "    with open('/content/predict.py', 'w') as file:\n",
        "        file.write(content)\n",
        "    print(\"Updated prepare_plot function to display IoU and Dice scores\")\n",
        "\n",
        "# Make sure the make_predictions function returns IoU and Dice\n",
        "with open('/content/predict.py', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Find make_predictions function\n",
        "make_predictions_start = content.find(\"def make_predictions\")\n",
        "if make_predictions_start != -1:\n",
        "    # If there's no return statement, add one\n",
        "    if \"return iou, dice\" not in content[make_predictions_start:]:\n",
        "        # Find the end of the function\n",
        "        next_def = content.find(\"def\", make_predictions_start + 1)\n",
        "        if next_def == -1:\n",
        "            next_def = len(content)\n",
        "\n",
        "        # Check if there's a prepare_plot call\n",
        "        prepare_plot_pos = content.rfind(\"prepare_plot\", make_predictions_start, next_def)\n",
        "        if prepare_plot_pos != -1:\n",
        "            # Find the end of this line\n",
        "            line_end = content.find(\"\\n\", prepare_plot_pos)\n",
        "            if line_end != -1:\n",
        "                # Insert return statement after prepare_plot call\n",
        "                content = content[:line_end+1] + \"        return iou, dice\\n\" + content[line_end+1:]\n",
        "\n",
        "                # Write back to the file\n",
        "                with open('/content/predict.py', 'w') as file:\n",
        "                    file.write(content)\n",
        "                print(\"Added return statement to make_predictions function\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gV79zt2gm2D",
        "outputId": "012ccd24-e3c5-4bbe-f41c-97e21e125c34"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added IoU and Dice calculation functions\n",
            "Modified make_predictions to calculate and print IoU\n",
            "Updated prepare_plot function to display IoU and Dice scores\n",
            "Added return statement to make_predictions function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px1MaCjqcCqn",
        "outputId": "aca3f80f-8027-469f-8090-9772be52fd66"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading up test image paths...\n",
            "Number of test images: 1408\n",
            "Selected 10 random images for evaluation\n",
            "[INFO] loading model...\n",
            "Model loaded successfully\n",
            "Starting prediction on test images...\n",
            "Processing image: MFSD/MSFD/1/face_crop/003008_1.jpg\n",
            "File: 003008_1.jpg, IoU: 0.5651, Dice: 0.7221\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_003008_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/002164_1.jpg\n",
            "File: 002164_1.jpg, IoU: 0.7383, Dice: 0.8494\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_002164_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/002538_1.jpg\n",
            "File: 002538_1.jpg, IoU: 0.7843, Dice: 0.8791\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_002538_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/004021_1.jpg\n",
            "File: 004021_1.jpg, IoU: 0.6370, Dice: 0.7783\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_004021_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/003042_1.jpg\n",
            "File: 003042_1.jpg, IoU: 0.7003, Dice: 0.8238\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_003042_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/005894_1.jpg\n",
            "File: 005894_1.jpg, IoU: 0.1604, Dice: 0.2765\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_005894_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/005956_1.jpg\n",
            "File: 005956_1.jpg, IoU: 0.7393, Dice: 0.8501\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_005956_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/005361_1.jpg\n",
            "File: 005361_1.jpg, IoU: 0.6840, Dice: 0.8123\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_005361_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/002929_1.jpg\n",
            "File: 002929_1.jpg, IoU: 0.7862, Dice: 0.8803\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_002929_1.png\n",
            "Processing image: MFSD/MSFD/1/face_crop/004965_1.jpg\n",
            "File: 004965_1.jpg, IoU: 0.6090, Dice: 0.7570\n",
            "Figure(1500x500)\n",
            "Visualization saved to visualizations/segmentation_004965_1.png\n",
            "\n",
            "Average metrics across 10 images:\n",
            "Average IoU: 0.6404\n",
            "Average Dice score: 0.7629\n"
          ]
        }
      ]
    }
  ]
}